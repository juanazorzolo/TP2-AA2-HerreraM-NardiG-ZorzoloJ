# Trabajo PrÃ¡ctico 2 - Aprendizaje AutomÃ¡tico II

Autores: Herrera Morena, Nardi Gianella BelÃ©n, Zorzolo Rubio Juana   
Carrera: Tecnicatura Universitaria en Inteligencia Artificial - FCEIA UNR  
AÃ±o: 2025


---

## Problema 1 - ClasificaciÃ³n de DÃ­gitos con Audio (Audio MNIST)

### DescripciÃ³n
Este problema aborda la tarea de clasificaciÃ³n de dÃ­gitos hablados del 0 al 9 utilizando un conjunto de datos de audio (`spoken_digit`) disponible en TensorFlow Datasets. El dataset contiene un total de 2500 clips de audio provenientes de 5 locutores (50 grabaciones por dÃ­gito por locutor).

### Objetivo
Construir un modelo de clasificaciÃ³n de dÃ­gitos hablados a partir de espectrogramas generados desde los clips de audio. Se entrenan y evalÃºan dos arquitecturas de redes neuronales:

- ğŸ§  **Modelo convolucional (CNN)** sobre espectrogramas.
- ğŸ” **Modelo recurrente (RNN)** sobre espectrogramas.

### Entrega
- Notebook en Google Colab con:
  - Preprocesamiento y anÃ¡lisis exploratorio del dataset.
  - ExtracciÃ³n de espectrogramas.
  - ImplementaciÃ³n de ambos modelos.
  - MÃ©tricas de evaluaciÃ³n (accuracy, matriz de confusiÃ³n, curvas de pÃ©rdida, etc.).
  - ComparaciÃ³n entre modelos.

---

## Problema 2 - Agentes para Flappy Bird con Q-Learning

### DescripciÃ³n
Se entrena un agente para jugar al juego Flappy Bird utilizando dos enfoques basados en Q-Learning. El entorno se construye con la librerÃ­a PyGame Learning Environment (PLE).

### Ejercicio A: Agente Q-Learning Tabular

- ğŸ§© **ImplementaciÃ³n**: Se completa el archivo `agentes/dq_agent.py`, discretizando el estado del juego y utilizando una Q-table.
- ğŸ‹ï¸â€â™‚ï¸ **Entrenamiento**: `train_q_agent.py` genera la Q-table y la guarda en un archivo `.pkl`.
- ğŸ® **Prueba**: El agente se prueba con `test_agent.py --agent agentes.dq_agent.QAgent`.

### Ejercicio B: Agente con Red Neuronal

- ğŸ§  **Entrenamiento de red**: Se entrena una red neuronal (`train_q_nn.py`) que aprende a aproximar la Q-table obtenida anteriormente.
- ğŸ¤– **Agente neuronal**: Se completa `agentes/nn_agent.py` para que el agente use la red para decidir acciones.
- ğŸ® **Prueba**: `test_agent.py --agent agentes.nn_agent.NNAgent`.

### AnÃ¡lisis Final

El archivo `problema2/conclusiones.md` contiene:
- IngenierÃ­a de caracterÃ­sticas (discretizaciÃ³n del estado).
- ComparaciÃ³n de resultados entre el agente tabular y el basado en red neuronal.

---

## Estructura del Proyecto

TP2-AA2/
â”œâ”€â”€ problema1/ # Notebook de clasificaciÃ³n de audio

â”œâ”€â”€ problema2/

â”‚ â”œâ”€â”€ agentes/

â”‚ â”‚ â”œâ”€â”€ base.py

â”‚ â”‚ â”œâ”€â”€ dq_agent.py

â”‚ â”‚ â”œâ”€â”€ nn_agent.py

â”‚ â”‚ â”œâ”€â”€ random_agent.py

â”‚ â”‚ â””â”€â”€ manual_agent.py

â”‚ â”œâ”€â”€ train_q_agent.py

â”‚ â”œâ”€â”€ train_q_nn.py

â”‚ â”œâ”€â”€ test_agent.py

â”‚ â”œâ”€â”€ flappy_birds_q_table.pkl

â”‚ â”œâ”€â”€ flappy_q_nn_model/ # Modelo SavedModel de TensorFlow

â”‚ â””â”€â”€ conclusiones.md

â”œâ”€â”€ requirements.txt

â””â”€â”€ README.md

---

## Requisitos

Para ejecutar localmente el problema 2, se requiere:

- Python 3.8+
- Virtualenv

InstalaciÃ³n:

```bash
python3 -m venv env
source env/bin/activate  # En Windows: env\Scripts\activate
pip install -r requirements.txt
```
---

## Instrucciones de Uso

### Ejecutar agentes en Flappy Bird

- Agente aleatorio:

```bash
python test_agent.py --agent agentes.random_agent.RandomAgent
```
- Agente manual:

```bash
python test_agent.py --agent agentes.manual_agent.ManualAgent
```

- Agente Q-learning entrenado:
```bash
python test_agent.py --agent agentes.dq_agent.QAgent
```

- Agente neuronal:
```bash
python test_agent.py --agent agentes.nn_agent.NNAgent
```

### Entrenamiento de Agentes

Entrenar agente Q-learning:

```bash
python train_q_agent.py
```
Entrenar red neuronal para aproximar la Q-table:

```bash
python train_q_nn.py
```
